# -*- coding: utf-8 -*-
"""Cats & Dogs Classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ygOfsGJIKi8QjThv3gPvr645YRCt1r6H
"""

import tensorflow as tf
from tensorflow import keras
from keras import layers
from keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import zipfile
import os
import numpy as np
from tensorflow.keras.preprocessing import image

dataset_url = "https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip"
path_to_zip = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=dataset_url, extract=False)

extract_path = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

with zipfile.ZipFile(path_to_zip, 'r') as zip_ref:
    zip_ref.extractall(os.path.dirname(path_to_zip))

base_dir = extract_path
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'validation')

print(f"Dataset Path: {base_dir}")
print(f"Train Path Exists: {os.path.exists(train_dir)}")
print(f"Validation Path Exists: {os.path.exists(val_dir)}")

# Load Dataset
train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    validation_split=0.2,
    subset="training",
    seed=1337,
    image_size=(180, 180),
    batch_size=32
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    val_dir,
    validation_split=0.2,
    subset="validation",
    seed=1337,
    image_size=(180, 180),
    batch_size=32
)

data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])

train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))

print(f"✅ Total batch di Training Set: {len(train_ds)}")
print(f"✅ Total batch di Validation Set: {len(val_ds)}")

# Import Model Pre-trained (MobileNetV2)
base_model = keras.applications.MobileNetV2(
    input_shape=(180, 180, 3),
    include_top=False,  # Buang fully connected layer bawaan
    weights='imagenet'
)

# Freeze Model Bawaan (Biar Gak Kehafalan Data Lama)
base_model.trainable = False  # Jangan di-train ulang dulu

# Bangun Model Baru
model = keras.Sequential([
    layers.Rescaling(1./255),  # Normalisasi gambar
    base_model,  # Pakai MobileNetV2 sebagai feature extractor
    layers.GlobalAveragePooling2D(),  # Pooling biar lebih stabil
    layers.Dropout(0.5),  # Dropout buat regularisasi
    layers.Dense(1, activation='sigmoid')  # Output (1 neuron → Binary Classification)
])

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # Pakai LR lebih kecil
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.summary()

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10,  # Bisa dinaikkan
    verbose=1
)

plt.plot(history.history['accuracy'], label='Akurasi Training')
plt.plot(history.history['val_accuracy'], label='Akurasi Validasi')
plt.xlabel('Epoch')
plt.ylabel('Akurasi')
plt.legend(loc='lower right')
plt.title('Akurasi Model')
plt.show()

# Load gambar test (Ganti dengan gambar yang mau dites)
img_path = "/content/dogs/dog.2009.jpg"

img = image.load_img(img_path, target_size=(180, 180))  # Resize gambar
img_array = image.img_to_array(img) / 255.0  # Normalisasi
img_array = np.expand_dims(img_array, axis=0)  # Tambah batch dimensi

# Prediksi
prediction = model.predict(img_array)
if prediction[0] > 0.5:
    print("🐶 AI bilang ini ANJING!")
else:
    print("🐱 AI bilang ini KUCING!")

model.save("cats_vs_dogs_model.h5")