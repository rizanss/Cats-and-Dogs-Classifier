import tensorflow as tf
from tensorflow import keras
from keras import layers
from keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import zipfile
import os

dataset_url = "https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip"
path_to_zip = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=dataset_url, extract=False)

extract_path = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

with zipfile.ZipFile(path_to_zip, 'r') as zip_ref:
    zip_ref.extractall(os.path.dirname(path_to_zip))
    
base_dir = extract_path
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'validation')

print(f"Dataset Path: {base_dir}")
print(f"Train Path Exists: {os.path.exists(train_dir)}")
print(f"Validation Path Exists: {os.path.exists(val_dir)}")

# Load Dataset
train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    validation_split=0.2,
    subset="training",
    seed=1337,
    image_size=(180, 180),
    batch_size=32
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    val_dir,
    validation_split=0.2,
    subset="validation",
    seed=1337,
    image_size=(180, 180),
    batch_size=32
)

data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])

train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))

print(f"✅ Total batch di Training Set: {len(train_ds)}")
print(f"✅ Total batch di Validation Set: {len(val_ds)}")

# Bangun model CNN (Convolutional Neural Network)
model = keras.Sequential([
    layers.Rescaling(1./255),  # Normalisasi gambar
    layers.Conv2D(32, 3, activation='relu'),  # Layer konvolusi pertama
    layers.MaxPooling2D(),  # Pooling buat ngecilin ukuran
    layers.Conv2D(64, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),  # Flatten biar jadi 1D
    layers.Dense(128, activation='relu'),  # Fully connected layer
    layers.Dropout(0.5),  # Dropout buat ngurangin overfitting
    layers.Dense(1, activation='sigmoid')  # Output layer (1 neuron: kucing/anjing)
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=20,
    callbacks=[early_stopping],
    verbose=1
)

# Karena model kurang optimal, maka dari itu ganti pake Fine-Tuning Transfer Learning menggunakan MobileNetV2

# Import Model Pre-trained (MobileNetV2)
base_model = keras.applications.MobileNetV2(
    input_shape=(180, 180, 3),
    include_top=False,  # Buang fully connected layer bawaan
    weights='imagenet'
)

# Freeze Model Bawaan (Biar Gak Kehafalan Data Lama)
base_model.trainable = False  # Jangan di-train ulang dulu

# Bangun Model Baru
model = keras.Sequential([
    layers.Rescaling(1./255),  # Normalisasi gambar
    base_model,  # Pakai MobileNetV2 sebagai feature extractor
    layers.GlobalAveragePooling2D(),  # Pooling biar lebih stabil
    layers.Dropout(0.5),  # Dropout buat regularisasi
    layers.Dense(1, activation='sigmoid')  # Output (1 neuron → Binary Classification)
])

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # Pakai LR lebih kecil
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Cek Arsitektur Model
model.summary()

# Train Model Transfer Learning
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10,  # Bisa dinaikkan
    verbose=1
)

plt.plot(history.history['accuracy'], label='Akurasi Training')
plt.plot(history.history['val_accuracy'], label='Akurasi Validasi')
plt.xlabel('Epoch')
plt.ylabel('Akurasi')
plt.legend(loc='lower right')
plt.title('Akurasi Model')
plt.show()
